{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "dd6de509",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Reading Input Data\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "filename1 = 'CS205_large_Data__22.txt' \n",
    "filename2 = 'CS205_small_Data__43.txt'\n",
    "\n",
    "with open(filename1, 'r') as file:\n",
    "    lines1 = file.readlines()\n",
    "data1 = []\n",
    "for line in lines1:\n",
    "    number_strings = line.split()\n",
    "    numbers = [float(num_str) for num_str in number_strings]\n",
    "    data1.append(numbers)\n",
    "\n",
    "\n",
    "\n",
    "data2 = []\n",
    "with open(filename2, 'r') as file:\n",
    "    lines2 = file.readlines()\n",
    "for line in lines2:\n",
    "    number_strings = line.split()\n",
    "    numbers = [float(num_str) for num_str in number_strings]\n",
    "    data2.append(numbers)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e6b795d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Nearest Neighbor Classifier\n",
    "import numpy as np\n",
    "import time\n",
    "def nn_classifier(data,features):\n",
    "\n",
    "    data = np.array(data)\n",
    "    data_points = data[:, features] \n",
    "    class_labels = data[:, 0]         \n",
    "    correct_count = 0\n",
    "    total_count = len(data_points) \n",
    "    for i in range(total_count):\n",
    "        data_point = data_points[i]\n",
    "        distances = np.linalg.norm(data_points - data_point, axis=1)  \n",
    "        distances[i] = np.inf  \n",
    "        closest_index = np.argmin(distances) \n",
    "        if class_labels[closest_index] == class_labels[i]:\n",
    "            correct_count += 1\n",
    "    accuracy = (correct_count / total_count) * 100 \n",
    "    return accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "ab6b938c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Forward Selection\n",
    "def forward_selection(data):\n",
    "    start_time = time.time()\n",
    "    features_added = []\n",
    "    class_labels = [point[0] for point in data]  \n",
    "    data_points = [point[1:] for point in data]  \n",
    "    no_features = len(data_points[0])\n",
    "    flag = 0\n",
    "    print(\"Beginning search:\\n\")\n",
    "\n",
    "    best_features = []\n",
    "    final_selection = []\n",
    "    global_best_accuracy = 0\n",
    "\n",
    "    for i in range(1,no_features+1):\n",
    "        current_selection = -1\n",
    "        best_accuracy = 0\n",
    "        for col in range(1,no_features+1):\n",
    "            if col not in best_features:\n",
    "                current_col = best_features + [col]\n",
    "                current_acc = nn_classifier(data, current_col)\n",
    "                print(f\"Using feature(s) {current_col} accuracy is {current_acc: .2f}%\")\n",
    "                if current_acc > best_accuracy:\n",
    "                    best_accuracy = current_acc\n",
    "                    current_selection = col\n",
    "               \n",
    "                   \n",
    "        if current_selection != -1:\n",
    "            best_features.append(current_selection)\n",
    "            if best_accuracy > global_best_accuracy:\n",
    "                final_selection = best_features[:]\n",
    "                global_best_accuracy = best_accuracy\n",
    "            else:\n",
    "                print(\"(Warning, Accuracy has decreased! Continuing search in case of local maxima)\")\n",
    "                   \n",
    "                \n",
    "            \n",
    "\n",
    "        print(f\"Feature set {best_features} was best, accuracy is {best_accuracy: .2f}%\\n\")\n",
    "\n",
    "    print(f\"Finished search!! The best feature subset is {final_selection}, which has an accuracy of {global_best_accuracy: .2f}%\\n\")\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"Time taken is:{duration: .2f} seconds\\n\")\n",
    "    return global_best_accuracy\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "fa7e3858",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Backward Elimination\n",
    "class_labels = [point[0] for point in data]  \n",
    "def backward_elimination(data):\n",
    "    start_time = time.time()\n",
    "    features_added = []\n",
    "    class_labels = [point[0] for point in data]  \n",
    "    data_points = [point[1:] for point in data]  \n",
    "    no_features = len(data_points[0])\n",
    "    flag =0\n",
    "\n",
    "    best_features = [i for i in range(1,no_features+1)]\n",
    "    final_selection = []\n",
    "    global_best_accuracy = nn_classifier(data,best_features)\n",
    "    print(f\"Using feature(s) {best_features} accuracy is {global_best_accuracy: .2f}%\")\n",
    "    selected_features = [i for i in range(1,no_features+1)]\n",
    "    \n",
    "    for i in range(1,no_features):\n",
    "        current_selection = -1\n",
    "        best_accuracy = 0\n",
    "        no_features\n",
    "        for col in range(1,no_features+1):\n",
    "\n",
    "            if col in best_features:\n",
    "                current_selection = col\n",
    "                current_col = [i for i in selected_features if i!=current_selection]\n",
    "                print(current_col)\n",
    "                current_acc = nn_classifier(data, current_col)\n",
    "                print(f\"Using feature(s) {current_col} accuracy is {current_acc: .2f}%\")\n",
    "                if current_acc > best_accuracy:\n",
    "                    best_accuracy = current_acc\n",
    "                    current_best = current_col\n",
    "                \n",
    "        if current_selection != -1:\n",
    "            best_features = current_best\n",
    "            if best_accuracy > global_best_accuracy:\n",
    "                final_selection = best_features[:]\n",
    "                global_best_accuracy = best_accuracy\n",
    "        selected_features = best_features\n",
    "        if best_accuracy > global_best_accuracy:\n",
    "            print(\"(Warning, Accuracy has decreased! Continuing search in case of local maxima)\")\n",
    "\n",
    "        print(f\"Feature set {best_features} was best, accuracy is {best_accuracy: .2f}%\\n\")\n",
    "\n",
    "    print(f\"Finished search!! The best feature subset is {final_selection}, which has an accuracy of {global_best_accuracy: .2f}%\\n\")\n",
    "    end_time = time.time()\n",
    "    duration = end_time - start_time\n",
    "    print(f\"Time taken is:{duration: .2f} seconds\\n\")\n",
    "    return global_best_accuracy\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "05354fb5",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Welcome to Anjana's Feature Selection Algorithm\n",
      "\n",
      "Type the number of the algorithm you want to run\n",
      "\n",
      "1. Forward Selection\n",
      "\n",
      "2. Backward Elimination\n",
      "\n",
      "2\n",
      "Select the dataset\n",
      "\n",
      "Type the number corresponding to the dataset you want\n",
      "\n",
      "1. Small Dataset\n",
      "\n",
      "2. Large Dataset\n",
      "\n",
      "1\n",
      "Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  69.80%\n",
      "[2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  70.60%\n",
      "[1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  69.40%\n",
      "[1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  74.40%\n",
      "[1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 3, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  73.40%\n",
      "[1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 3, 4, 6, 7, 8, 9, 10, 11, 12] accuracy is  71.60%\n",
      "[1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 3, 4, 5, 7, 8, 9, 10, 11, 12] accuracy is  65.20%\n",
      "[1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 3, 4, 5, 6, 8, 9, 10, 11, 12] accuracy is  73.00%\n",
      "[1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 3, 4, 5, 6, 7, 9, 10, 11, 12] accuracy is  72.60%\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12] accuracy is  70.00%\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12]\n",
      "Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 11, 12] accuracy is  72.80%\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12]\n",
      "Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 12] accuracy is  71.80%\n",
      "[1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is  71.00%\n",
      "Feature set [1, 2, 4, 5, 6, 7, 8, 9, 10, 11, 12] was best, accuracy is  74.40%\n",
      "\n",
      "[2, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [2, 4, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  70.60%\n",
      "[1, 4, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 4, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  73.60%\n",
      "[1, 2, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  75.80%\n",
      "[1, 2, 4, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 4, 6, 7, 8, 9, 10, 11, 12] accuracy is  72.00%\n",
      "[1, 2, 4, 5, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 4, 5, 7, 8, 9, 10, 11, 12] accuracy is  66.20%\n",
      "[1, 2, 4, 5, 6, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 4, 5, 6, 8, 9, 10, 11, 12] accuracy is  74.60%\n",
      "[1, 2, 4, 5, 6, 7, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 4, 5, 6, 7, 9, 10, 11, 12] accuracy is  73.60%\n",
      "[1, 2, 4, 5, 6, 7, 8, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 4, 5, 6, 7, 8, 10, 11, 12] accuracy is  70.00%\n",
      "[1, 2, 4, 5, 6, 7, 8, 9, 11, 12]\n",
      "Using feature(s) [1, 2, 4, 5, 6, 7, 8, 9, 11, 12] accuracy is  72.20%\n",
      "[1, 2, 4, 5, 6, 7, 8, 9, 10, 12]\n",
      "Using feature(s) [1, 2, 4, 5, 6, 7, 8, 9, 10, 12] accuracy is  73.40%\n",
      "[1, 2, 4, 5, 6, 7, 8, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 4, 5, 6, 7, 8, 9, 10, 11] accuracy is  75.80%\n",
      "Feature set [1, 2, 5, 6, 7, 8, 9, 10, 11, 12] was best, accuracy is  75.80%\n",
      "\n",
      "[2, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [2, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  74.60%\n",
      "[1, 5, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 5, 6, 7, 8, 9, 10, 11, 12] accuracy is  75.20%\n",
      "[1, 2, 6, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 6, 7, 8, 9, 10, 11, 12] accuracy is  74.00%\n",
      "[1, 2, 5, 7, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 5, 7, 8, 9, 10, 11, 12] accuracy is  67.80%\n",
      "[1, 2, 5, 6, 8, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 5, 6, 8, 9, 10, 11, 12] accuracy is  74.60%\n",
      "[1, 2, 5, 6, 7, 9, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 5, 6, 7, 9, 10, 11, 12] accuracy is  76.20%\n",
      "[1, 2, 5, 6, 7, 8, 10, 11, 12]\n",
      "Using feature(s) [1, 2, 5, 6, 7, 8, 10, 11, 12] accuracy is  72.60%\n",
      "[1, 2, 5, 6, 7, 8, 9, 11, 12]\n",
      "Using feature(s) [1, 2, 5, 6, 7, 8, 9, 11, 12] accuracy is  73.80%\n",
      "[1, 2, 5, 6, 7, 8, 9, 10, 12]\n",
      "Using feature(s) [1, 2, 5, 6, 7, 8, 9, 10, 12] accuracy is  75.80%\n",
      "[1, 2, 5, 6, 7, 8, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 5, 6, 7, 8, 9, 10, 11] accuracy is  77.40%\n",
      "Feature set [1, 2, 5, 6, 7, 8, 9, 10, 11] was best, accuracy is  77.40%\n",
      "\n",
      "[2, 5, 6, 7, 8, 9, 10, 11]\n",
      "Using feature(s) [2, 5, 6, 7, 8, 9, 10, 11] accuracy is  78.00%\n",
      "[1, 5, 6, 7, 8, 9, 10, 11]\n",
      "Using feature(s) [1, 5, 6, 7, 8, 9, 10, 11] accuracy is  74.60%\n",
      "[1, 2, 6, 7, 8, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 6, 7, 8, 9, 10, 11] accuracy is  76.60%\n",
      "[1, 2, 5, 7, 8, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 5, 7, 8, 9, 10, 11] accuracy is  71.40%\n",
      "[1, 2, 5, 6, 8, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 5, 6, 8, 9, 10, 11] accuracy is  79.40%\n",
      "[1, 2, 5, 6, 7, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 5, 6, 7, 9, 10, 11] accuracy is  77.40%\n",
      "[1, 2, 5, 6, 7, 8, 10, 11]\n",
      "Using feature(s) [1, 2, 5, 6, 7, 8, 10, 11] accuracy is  73.60%\n",
      "[1, 2, 5, 6, 7, 8, 9, 11]\n",
      "Using feature(s) [1, 2, 5, 6, 7, 8, 9, 11] accuracy is  75.80%\n",
      "[1, 2, 5, 6, 7, 8, 9, 10]\n",
      "Using feature(s) [1, 2, 5, 6, 7, 8, 9, 10] accuracy is  76.40%\n",
      "Feature set [1, 2, 5, 6, 8, 9, 10, 11] was best, accuracy is  79.40%\n",
      "\n",
      "[2, 5, 6, 8, 9, 10, 11]\n",
      "Using feature(s) [2, 5, 6, 8, 9, 10, 11] accuracy is  78.20%\n",
      "[1, 5, 6, 8, 9, 10, 11]\n",
      "Using feature(s) [1, 5, 6, 8, 9, 10, 11] accuracy is  77.80%\n",
      "[1, 2, 6, 8, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 6, 8, 9, 10, 11] accuracy is  79.40%\n",
      "[1, 2, 5, 8, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 5, 8, 9, 10, 11] accuracy is  71.20%\n",
      "[1, 2, 5, 6, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 5, 6, 9, 10, 11] accuracy is  79.60%\n",
      "[1, 2, 5, 6, 8, 10, 11]\n",
      "Using feature(s) [1, 2, 5, 6, 8, 10, 11] accuracy is  74.60%\n",
      "[1, 2, 5, 6, 8, 9, 11]\n",
      "Using feature(s) [1, 2, 5, 6, 8, 9, 11] accuracy is  77.80%\n",
      "[1, 2, 5, 6, 8, 9, 10]\n",
      "Using feature(s) [1, 2, 5, 6, 8, 9, 10] accuracy is  79.40%\n",
      "Feature set [1, 2, 5, 6, 9, 10, 11] was best, accuracy is  79.60%\n",
      "\n",
      "[2, 5, 6, 9, 10, 11]\n",
      "Using feature(s) [2, 5, 6, 9, 10, 11] accuracy is  80.20%\n",
      "[1, 5, 6, 9, 10, 11]\n",
      "Using feature(s) [1, 5, 6, 9, 10, 11] accuracy is  84.00%\n",
      "[1, 2, 6, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 6, 9, 10, 11] accuracy is  80.60%\n",
      "[1, 2, 5, 9, 10, 11]\n",
      "Using feature(s) [1, 2, 5, 9, 10, 11] accuracy is  70.20%\n",
      "[1, 2, 5, 6, 10, 11]\n",
      "Using feature(s) [1, 2, 5, 6, 10, 11] accuracy is  75.60%\n",
      "[1, 2, 5, 6, 9, 11]\n",
      "Using feature(s) [1, 2, 5, 6, 9, 11] accuracy is  80.20%\n",
      "[1, 2, 5, 6, 9, 10]\n",
      "Using feature(s) [1, 2, 5, 6, 9, 10] accuracy is  80.60%\n",
      "Feature set [1, 5, 6, 9, 10, 11] was best, accuracy is  84.00%\n",
      "\n",
      "[5, 6, 9, 10, 11]\n",
      "Using feature(s) [5, 6, 9, 10, 11] accuracy is  83.80%\n",
      "[1, 6, 9, 10, 11]\n",
      "Using feature(s) [1, 6, 9, 10, 11] accuracy is  84.00%\n",
      "[1, 5, 9, 10, 11]\n",
      "Using feature(s) [1, 5, 9, 10, 11] accuracy is  72.80%\n",
      "[1, 5, 6, 10, 11]\n",
      "Using feature(s) [1, 5, 6, 10, 11] accuracy is  76.60%\n",
      "[1, 5, 6, 9, 11]\n",
      "Using feature(s) [1, 5, 6, 9, 11] accuracy is  84.80%\n",
      "[1, 5, 6, 9, 10]\n",
      "Using feature(s) [1, 5, 6, 9, 10] accuracy is  86.60%\n",
      "Feature set [1, 5, 6, 9, 10] was best, accuracy is  86.60%\n",
      "\n",
      "[5, 6, 9, 10]\n",
      "Using feature(s) [5, 6, 9, 10] accuracy is  86.00%\n",
      "[1, 6, 9, 10]\n",
      "Using feature(s) [1, 6, 9, 10] accuracy is  87.80%\n",
      "[1, 5, 9, 10]\n",
      "Using feature(s) [1, 5, 9, 10] accuracy is  72.40%\n",
      "[1, 5, 6, 10]\n",
      "Using feature(s) [1, 5, 6, 10] accuracy is  79.20%\n",
      "[1, 5, 6, 9]\n",
      "Using feature(s) [1, 5, 6, 9] accuracy is  86.40%\n",
      "Feature set [1, 6, 9, 10] was best, accuracy is  87.80%\n",
      "\n",
      "[6, 9, 10]\n",
      "Using feature(s) [6, 9, 10] accuracy is  89.80%\n",
      "[1, 9, 10]\n",
      "Using feature(s) [1, 9, 10] accuracy is  73.00%\n",
      "[1, 6, 10]\n",
      "Using feature(s) [1, 6, 10] accuracy is  83.40%\n",
      "[1, 6, 9]\n",
      "Using feature(s) [1, 6, 9] accuracy is  91.20%\n",
      "Feature set [1, 6, 9] was best, accuracy is  91.20%\n",
      "\n",
      "[6, 9]\n",
      "Using feature(s) [6, 9] accuracy is  97.40%\n",
      "[1, 9]\n",
      "Using feature(s) [1, 9] accuracy is  71.00%\n",
      "[1, 6]\n",
      "Using feature(s) [1, 6] accuracy is  85.40%\n",
      "Feature set [6, 9] was best, accuracy is  97.40%\n",
      "\n",
      "[9]\n",
      "Using feature(s) [9] accuracy is  73.40%\n",
      "[6]\n",
      "Using feature(s) [6] accuracy is  85.80%\n",
      "Feature set [6] was best, accuracy is  85.80%\n",
      "\n",
      "Finished search!! The best feature subset is [6, 9], which has an accuracy of  97.40%\n",
      "\n",
      "Time taken is: 1.83 seconds\n",
      "\n",
      "Running nearest neighbor with all 4 features, using leave-one-out evaluation, I get an accuracy of  97.40%\n"
     ]
    }
   ],
   "source": [
    "#User Console\n",
    "print(\"Welcome to Anjana's Feature Selection Algorithm\\n\")\n",
    "print(\"Type the number of the algorithm you want to run\\n\")\n",
    "print(\"1. Forward Selection\\n\")\n",
    "print(\"2. Backward Elimination\\n\")\n",
    "algo_no = int(input())\n",
    "print(\"Select the dataset\\n\")\n",
    "print(\"Type the number corresponding to the dataset you want\\n\")\n",
    "print(\"1. Small Dataset\\n\")\n",
    "print(\"2. Large Dataset\\n\")\n",
    "dataset_no = int(input())\n",
    "if(algo_no==1):\n",
    "    if(dataset_no == 1):\n",
    "        print(f\"Running nearest neighbor with all 4 features, using leave one out evaluation, I get an accuracy of {forward_selection(data2): .2f}%\")\n",
    "    else:\n",
    "        print(f\"Running nearest neighbor with all 4 features, using leave-one-out evaluation, I get an accuracy of {forward_selection(data1): .2f}%\")\n",
    "        \n",
    "\n",
    "elif(algo_no==2):\n",
    "    if(dataset_no == 1):\n",
    "           print(f\"Running nearest neighbor with all 4 features, using leave-one-out evaluation, I get an accuracy of {backward_elimination(data2): .2f}%\")\n",
    "    else:\n",
    "        print(f\"Running nearest neighbor with all 4 features, using leave-one-out evaluation, I get an accuracy of {backward_elimination(data1): .2f}%\")\n",
    "        \n",
    "           \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ab61a09",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
